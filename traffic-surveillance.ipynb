{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Traffic Surveillance\n",
    "\n",
    "This notebook will detail an implementations for traffic surveillance"
   ],
   "id": "73c00e5a2cf8eab3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prerequisites\n",
    "\n",
    "Let's import all the necessary dependencies to make t"
   ],
   "id": "752669756fd42b20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:49:57.492098Z",
     "start_time": "2024-10-13T17:49:57.165390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "3dd16b818dd9a189",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This notebook integrates the **NVIDIA CUDA Toolkit** to accelerate processes defined in the OpenCV libraries. The CUDA Toolkit provides the development environment and libraries necessary to run GPU-accelerated applications, while **PyTorch** provides a high-level interface for GPU-accelerated machine learning tasks using CUDA.\n",
    "\n",
    "Following these steps you will be able to run Pytorch on cuda GPU:\n",
    "\n",
    "- See if you have an NVIDIA gpu that supports *CUDA*. You can check whether your supports CUDA on the [Nvidia CUDA GPUs](https://developer.nvidia.com/cuda-gpus) list\n",
    "- The *NVIDIA drivers* allow your operating system to communicate with the GPU. Download the latest driver for your GPU from [NVIDIA GPU drivers](https://www.nvidia.com/en-us/drivers/)\n",
    "- The *NVIDIA CUDA¬Æ Deep Neural Network* library (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. Download link: [Nvidia cuDNN](https://developer.nvidia.com/cudnn)\n",
    "- The *CUDA Toolkit* provides the development environment and libraries necessary to run GPU-accelerated applications. Download the [Nvidia CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit), and add CUDA binaries to your system's PATH.\n",
    "- Install *PyTorch with CUDA* support by visiting the [PyTorch installation](https://pytorch.org/get-started/locally/) page and choosing the appropriate options.\n",
    "\n",
    "After completing the above steps, verify CUDA is available by running the following in a Python "
   ],
   "id": "b4189ef9a3d351d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T18:02:23.694426Z",
     "start_time": "2024-10-13T18:02:22.448864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Set up device working\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "print(\"Device used:\", device)"
   ],
   "id": "aa4675c2790804b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.4.1+cu121\n",
      "CUDA Available: False\n",
      "CUDA Device Count: 0\n",
      "Device used: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davevarga/Projects/virtenvs/bwim-venv/lib/python3.12/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Implementation\n",
    "\n",
    "For a real-time traffic surveillance system that detects vehicle positions, reads license plates, and locates windshields, a multi-stage approach with different models can work best.\n",
    "\n",
    "### Vehicle detection\n",
    "\n",
    "At first, we need to detect the vehicles on our image. We not only need cars, but also trucks,  buses, and other large and heavy vehicles, as these yield the highest impact in bridge life.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The *dataset* choise is highly relevant, therefore we chose the **UA-DETRAC** dataset, which was specifically designed for vehicle detection and tracking in traffic surveillance systems. `Containing 140k images, with over 825k labeled vehicles from 10 different locations, it includes multiple vehicle types (car, bus, truck, van)."
   ],
   "id": "a1163d86981d1d47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:50:25.573880Z",
     "start_time": "2024-10-13T17:50:25.297268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download('dtrnngc/ua-detrac-dataset')"
   ],
   "id": "103e113f991c50f8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When training a model for traffic surveillance, dataset selection and preparation are crucial for achieving accurate and robust results. Here are key considerations regarding datasets:\n",
    "\n",
    "- In case of BWIM surveillance systems, detection of trucks, and buses are considerably more important, as they account highly in *hid romlasi rata*. Therefore, we must ensure that the dataset *includes heavy vehicles* like trucks, buses, etc. \n",
    "- **Environmental conditions** play an important role in achieving robust models. Consequently different locations, camera angles, environmental conditions and times of day should be considered.\n",
    "- **Data Quality:** High resolution images, not only allows the model to learn small details, but is crucial for following procedures, such as license plate recognition, while accurate labeling is important to ensure good performance. \n",
    "- **Data Balancing:** To optimize regression, every batch should sample proportionally across classes, environments and scenarios. In case of underrepresented classes over-sampling is suggested.\n",
    "- **Domain Specific Data:** Although a balanced distribution is important, the dataset should mimic the real-world traffic surveillance system's use cases.\n",
    "- **Data augmentation:** robustness can be improved using image transformations like noise injection, color and lightning manipulation, to improve performance under different scenarios, although might hurt training proficiency.\n",
    "- **Normalization:** Normalizing the images (e.g., resizing, contrast normalization) ensures that they are fed into the model in a consistent format, therefore the model does not have to learn unnecessary features.\n",
    "\n",
    "There is also a legal and ethical consideration, regarding data anonymity, license plate privacy, as well as dataset licensing. This responsibility falls on the user of the dataset."
   ],
   "id": "a875245a8fb4a4df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:57:35.971003Z",
     "start_time": "2024-10-13T17:57:35.233151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Specify paths\n",
    "dataset_yaml = './datasets/uc-detrac/uc-detrac.yaml'  # Path to dataset.yaml file\n",
    "model_save_dir = './models'  # Directory where the model will be saved\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "\n",
    "# Load the YOLOv8n (small) pre-trained model\n",
    "model = YOLO('yolov8s.pt')  \n",
    "\n",
    "# Train the model using the dataset\n",
    "results = model.train(\n",
    "    data=dataset_yaml,  # Path to the dataset YAML file\n",
    "    epochs=10,          # Number of epochs (adjust based on your needs)\n",
    "    batch=64,           # Batch size (adjust based on your hardware)\n",
    "    imgsz=640,          # Image size (YOLOv8 typically uses 640x640)\n",
    "    name='yolov8_traffic_surveillance',  # Name of the run\n",
    "    device=device,\n",
    "    fraction=0.1        # Allows for training on a subset of the full dataset\n",
    ")\n",
    "\n",
    "# Save the final model in ./models directory\n",
    "model_path = os.path.join(model_save_dir, 'yolov8_car_detection.pt')\n",
    "print(f\"Model saved at {model_path}\")\n"
   ],
   "id": "ea2a6e68f2823e18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.12 available üòÉ Update with 'pip install -U ultralytics'\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov8s.pt, data=./datasets/uc-detrac/uc-detrac.yaml, epochs=10, time=None, patience=100, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=yolov8_traffic_surveillance, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=0.1, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8_traffic_surveillance\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'datasets/uc-detrac/uc-detrac.yaml' error ‚ùå './datasets/uc-detrac/uc-detrac.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/Projects/virtenvs/bwim-venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:557\u001B[0m, in \u001B[0;36mBaseTrainer.get_dataset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myaml\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myml\u001B[39m\u001B[38;5;124m\"\u001B[39m} \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mtask \u001B[38;5;129;01min\u001B[39;00m {\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdetect\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    553\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msegment\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    554\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpose\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    555\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobb\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    556\u001B[0m }:\n\u001B[0;32m--> 557\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_det_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    558\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myaml_file\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m data:\n",
      "File \u001B[0;32m~/Projects/virtenvs/bwim-venv/lib/python3.12/site-packages/ultralytics/data/utils.py:269\u001B[0m, in \u001B[0;36mcheck_det_dataset\u001B[0;34m(dataset, autodownload)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;124;03mDownload, verify, and/or unzip a dataset if not found locally.\u001B[39;00m\n\u001B[1;32m    257\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;124;03m    (dict): Parsed dataset information and paths.\u001B[39;00m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 269\u001B[0m file \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;66;03m# Download (optional)\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/virtenvs/bwim-venv/lib/python3.12/site-packages/ultralytics/utils/checks.py:521\u001B[0m, in \u001B[0;36mcheck_file\u001B[0;34m(file, suffix, download, download_dir, hard)\u001B[0m\n\u001B[1;32m    520\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m files \u001B[38;5;129;01mand\u001B[39;00m hard:\n\u001B[0;32m--> 521\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m does not exist\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    522\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(files) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m hard:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: './datasets/uc-detrac/uc-detrac.yaml' does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m model \u001B[38;5;241m=\u001B[39m YOLO(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124myolov8s.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)  \n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Train the model using the dataset\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_yaml\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Path to the dataset YAML file\u001B[39;49;00m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m          \u001B[49m\u001B[38;5;66;43;03m# Number of epochs (adjust based on your needs)\u001B[39;49;00m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m           \u001B[49m\u001B[38;5;66;43;03m# Batch size (adjust based on your hardware)\u001B[39;49;00m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimgsz\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m640\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m          \u001B[49m\u001B[38;5;66;43;03m# Image size (YOLOv8 typically uses 640x640)\u001B[39;49;00m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43myolov8_traffic_surveillance\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Name of the run\u001B[39;49;00m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfraction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Allows for training on a subset of the full dataset\u001B[39;49;00m\n\u001B[1;32m     24\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Save the final model in ./models directory\u001B[39;00m\n\u001B[1;32m     27\u001B[0m model_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(model_save_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124myolov8_car_detection.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/virtenvs/bwim-venv/lib/python3.12/site-packages/ultralytics/engine/model.py:796\u001B[0m, in \u001B[0;36mModel.train\u001B[0;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[1;32m    793\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresume\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    794\u001B[0m     args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresume\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mckpt_path\n\u001B[0;32m--> 796\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_smart_load\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrainer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43moverrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_callbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresume\u001B[39m\u001B[38;5;124m\"\u001B[39m):  \u001B[38;5;66;03m# manually set model only if not resuming\u001B[39;00m\n\u001B[1;32m    798\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mget_model(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mckpt \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, cfg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39myaml)\n",
      "File \u001B[0;32m~/Projects/virtenvs/bwim-venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:133\u001B[0m, in \u001B[0;36mBaseTrainer.__init__\u001B[0;34m(self, cfg, overrides, _callbacks)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m check_model_file_from_stem(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mmodel)  \u001B[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001B[39;00m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001B[38;5;66;03m# avoid auto-downloading dataset multiple times\u001B[39;00m\n\u001B[0;32m--> 133\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainset, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtestset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mema \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# Optimization utils init\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/virtenvs/bwim-venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:561\u001B[0m, in \u001B[0;36mBaseTrainer.get_dataset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    559\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myaml_file\u001B[39m\u001B[38;5;124m\"\u001B[39m]  \u001B[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001B[39;00m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 561\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(emojis(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclean_url(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdata)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m error ‚ùå \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    562\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m], data\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m data\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Dataset 'datasets/uc-detrac/uc-detrac.yaml' error ‚ùå './datasets/uc-detrac/uc-detrac.yaml' does not exist"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
